<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>慢 慢 悠</title>
  
  <subtitle>因无所住，而生其心</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://mydiscat.cn/"/>
  <updated>2018-10-31T12:31:58.092Z</updated>
  <id>https://mydiscat.cn/</id>
  
  <author>
    <name>远方的猫</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>准备开发环境</title>
    <link href="https://mydiscat.cn/category/2018/10/31/Development%20preparation.html"/>
    <id>https://mydiscat.cn/category/2018/10/31/Development preparation.html</id>
    <published>2018-10-30T16:00:00.000Z</published>
    <updated>2018-10-31T12:31:58.092Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p>##开篇<br>换电脑，记录下安装的应用，留作参考<br>先将就电脑文件全部备份到百度云，然后开始安装系统、基本应用、开发环境</p><p>###<strong>基本应用</strong> </p><blockquote><p><a href="http://www.winrar.com.cn/" target="_blank" rel="noopener">WinRAR</a> 、<a href="http://office.qq.com/download.html" target="_blank" rel="noopener">TIM</a>、<a href="https://www.dingtalk.com/?source=2202&amp;lwfrom=2017120202092064209309201" target="_blank" rel="noopener">钉钉</a> 、<a href="http://note.youdao.com/" target="_blank" rel="noopener">有道云笔记</a> 、<a href="">百度云</a> 、<a href="http://www.firefox.com.cn/" target="_blank" rel="noopener">火狐</a> / <a href="https://pc.qq.com/detail/1/detail_2661.html" target="_blank" rel="noopener">谷歌浏览器</a> （<a href="">谷歌插件</a>）、<a href="https://pc.qq.com/detail/1/detail_1061.html" target="_blank" rel="noopener">everything</a> 、<a href="https://pinyin.sogou.com/" target="_blank" rel="noopener">输入法</a> 、<a href="https://music.163.com/#/download" target="_blank" rel="noopener">网易云音乐</a></p></blockquote><a id="more"></a><hr><h2 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h2><blockquote><p>虚拟机：      <a href="https://www.jianshu.com/p/1d68f76d9b38" target="_blank" rel="noopener">JDK</a><br>服务器： <a href="http://blog.51cto.com/freeloda/1299644" target="_blank" rel="noopener">Tomcat</a> 、<a href="https://github.com/aalansehaiyang/technology-talk/blob/master/web/Nginx.md" target="_blank" rel="noopener">nginx</a><br>数据库：<a href="http://www.oracle.com/technetwork/cn/database/enterprise-edition/downloads/index.html" target="_blank" rel="noopener">Oracle</a> 、<a href="https://www.mysql.com/downloads/" target="_blank" rel="noopener">mysql</a> 、<a href="https://www.jianshu.com/p/69cd985d7111" target="_blank" rel="noopener">Oracle Windows安装</a><br>SVN：<a href="https://tortoisesvn.net/downloads.html" target="_blank" rel="noopener">TortoiseSVN</a><br>Git：<a href="https://www.git-scm.com/download/" target="_blank" rel="noopener">git</a>  、 <a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">git廖雪峰教程</a><br>接口调试：<a href="https://www.getpostman.com/" target="_blank" rel="noopener">Postman</a><br>数据库连接：<a href="https://blog.csdn.net/MAOZEXIJR/article/details/77773860?locationNum=7&amp;fps=1" target="_blank" rel="noopener">navicat_premium</a><br>ETL工具： <a href="http://www.kettle.net.cn/" target="_blank" rel="noopener">kettle</a></p></blockquote><hr><blockquote><p>开发工具： <a href="http://www.baidu.com/link?url=AVgZmK7jFqgK1tIQYWx5fS9kcyi5n8BjjtJ_-NuEumK-9FvfUqzCSasGxEw_-x-JkV8LbS_JMBKwbjxzd3n7SFhTd4osDQEsT6_5XF0vtd_" target="_blank" rel="noopener">IntelliJ <em>IDEA</em></a><br>远程连接：<a href="https://jingyan.baidu.com/article/c1a3101ea80badde656deb83.html" target="_blank" rel="noopener">SecureCRT/SecureFX</a><br>反编译：<a href="http://www.softpedia.com/get/Programming/Debuggers-Decompilers-Dissasemblers/JD-GUI.shtml" target="_blank" rel="noopener">jd-gui</a><br>应用容器：<a href="https://www.docker.com/get-started" target="_blank" rel="noopener">Dockor</a><br>持续集成：<a href="https://blog.csdn.net/qq_26848099/article/details/78901240" target="_blank" rel="noopener">Jenkins</a><br>文本编辑：<a href="https://notepad-plus-plus.org/" target="_blank" rel="noopener">notepad</a><br>思维导图：<a href="https://www.xmind.cn/zen/" target="_blank" rel="noopener">Xmind</a><br>虚拟化：<a href="https://www.vmware.com/cn.html" target="_blank" rel="noopener">VMware</a> 、<a href="https://www.centos.org/download/" target="_blank" rel="noopener">CentOS7</a><br>Python : <a href="https://www.python.org/" target="_blank" rel="noopener">Python</a> 、<a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" target="_blank" rel="noopener">Python廖雪峰教程</a><br>Node.js：<a href="https://nodejs.org/zh-cn/" target="_blank" rel="noopener">Node.js</a><br>正则：<a href="http://www.pc0359.cn/downinfo/41229.html" target="_blank" rel="noopener">regexbuddy</a></p></blockquote><p>[Create：2018年8月14日]</p><hr><hr>]]></content>
    
    <summary type="html">
    
      工作中常用的工具及应用，持续更新
    
    </summary>
    
      <category term="Java" scheme="https://mydiscat.cn/categories/Java/"/>
    
    
      <category term="Java" scheme="https://mydiscat.cn/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>hadoop分布式集群搭建</title>
    <link href="https://mydiscat.cn/category/2018/10/31/Hadoop%20distributed%20cluster%20construction.html"/>
    <id>https://mydiscat.cn/category/2018/10/31/Hadoop distributed cluster construction.html</id>
    <published>2018-10-30T16:00:00.000Z</published>
    <updated>2018-10-31T12:32:07.424Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><strong>基础环境准备</strong></p><p>1、软件环境</p><blockquote><p>centos 6.5 三台服务器分配的IP地址：8/9/10<br>jdk1.8<br>hadoop使用2.7.4版本</p></blockquote><a id="more"></a><p>2、host配置和主机名（三台）</p><p>修改四台服务器的hosts文件<br>vim /etc/hosts</p><blockquote><p>192.168.0.8 hadoop-master<br>   192.168.0.9 hadoop-slave1<br>   192.168.0.10 hadoop-slave2</p></blockquote><p>分别修改服务器的主机名:HOSTNAME，master为例说明<br>vi /etc/sysconfig/network</p><blockquote><p>HOSTNAME=hadoop-master<br>执行reboot后生效，完成之后依次修改其它salve服务器为： hadoop-slave1~2。</p></blockquote><p>3、服务器安装jdk（三台）<br>建议使用yum安装jdk,也可以自行下载安装我是下载了1.8)</p><blockquote><p>yum -y install java-1.7.0-openjdk*<br>下载的通过ssh复制到服务器</p></blockquote><p>配置环境变量，修改配置文件vim /etc/profile</p><blockquote><p>export JAVA_HOME=/usr/java/jdk1.8.0_152<br>export PATH= \$JAVA_HOME/bin:\$PATH<br>export CLASSPATH=.:\$JAVA_HOME/lib/dt.jar:\$JAVA_HOME/lib/tools.jar</p></blockquote><p>使用souce命令让立刻生效</p><blockquote><p>source /etc/profile</p></blockquote><p>###免密登陆<br>1、首先关闭四台服务器的防火墙和SELINUX</p><ul><li><p>查看防火墙状态</p><blockquote><p>service iptables status</p></blockquote></li><li><p>关闭防火墙</p><blockquote><p>service iptables stop<br>chkconfig iptables off</p></blockquote></li><li><p>关闭SELINUX后，需要重启服务器</p></li></ul><blockquote><p>– 关闭SELINUX<br># vim /etc/selinux/config<br>– 注释掉<br>#SELINUX=enforcing<br>#SELINUXTYPE=targeted<br>– 添加<br>SELINUX=disabled</p></blockquote><p>2、免密码登录本机<br>下面以配置hadoop-master本机无密码登录为例进行讲解，用户需参照下面步骤完成h-salve1~2三台子节点机器的本机无密码登录<br>1） 生产秘钥</p><blockquote><p>ssh-keygen -t rsa</p></blockquote><p>2）将公钥追加到”authorized_keys”文件</p><blockquote><p>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</p></blockquote><p>3）赋予权限</p><blockquote><p>chmod 600 .ssh/authorized_keys</p></blockquote><p>4）验证本机能无密码访问</p><blockquote><p>ssh hadoop-master<br>最后，依次配置h-salve1~2无密码访问</p></blockquote><p>3、hadoop-master本机无密码登录hadoop-slave1、hadoop-slave2以hadoop-master无密码登录hadoop-slave1为例讲解：</p><p>1）登录hadoop-slave1 ，复制hadoop-master服务器的公钥”id_rsa.pub”到hadoop-slave1服务器的”root”目录下。</p><blockquote><p>scp root@hadoop-master:/root/.ssh/id_rsa.pub /root/</p></blockquote><p>2）将hadoop-master的公钥（id_rsa.pub）追加到hadoop-slave1的authorized_keys中</p><blockquote><p>cat id_rsa.pub &gt;&gt; .ssh/authorized_keys<br>rm -rf  id_rsa.pub</p></blockquote><p>3）在 hadoop-master上面测试</p><blockquote><p>ssh  hadoop-slave1</p></blockquote><p>4、下面以hadoop-slave1无密码登录hadoop-master为例进行讲解，用户需参照下面步骤完成hadoop-slave2无密码登录hadoop-master。</p><p>1）登录hadoop-master，复制hadoop-slave1服务器的公钥”id_rsa.pub”到hadoop-master服务器的”/root/”目录下。</p><blockquote><p>scp root@hadoop-slave1:/root/.ssh/id_rsa.pub /root/</p></blockquote><p>2）将hadoop-slave1的公钥（id_rsa.pub）追加到hadoop-master的authorized_keys中。</p><blockquote><p>cat id_rsa.pub &gt;&gt; .ssh/authorized_keys<br>rm -rf  id_rsa.pub //删除id_rsa.pub</p></blockquote><p>3）在 hadoop-slave1上面测试</p><blockquote><p>ssh  hadoop-master<br>依次配置 hadoop-slave2</p></blockquote><p>到此主从的无密登录已经完成了</p><p>####Hadoop环境搭建<br><strong>配置hadoop-master的hadoop环境</strong><br>1、hadoop-master上 解压缩安装包及创建基本目录</p><blockquote><p>#下载  (我已经下好2.7.4版本)<br>wget <a href="http://apache.claz.org/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz" target="_blank" rel="noopener">http://apache.claz.org/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz</a><br>#解压<br>tar -xzvf  hadoop-2.7.3.tar.gz    -C /usr/local<br>#重命名<br>mv  hadoop-2.7.3  hadoop</p></blockquote><p>2、 配置hadoop-master的hadoop环境变量</p><p>1）配置环境变量，修改配置文件vi /etc/profile</p><blockquote><p>export HADOOP_HOME=/home/hadoop/hadoop<br>export PATH=\$PATH:\$HADOOP_HOME/bin </p></blockquote><p>使得hadoop命令在当前终端立即生效</p><blockquote><p>source /etc/profile</p></blockquote><p>下面配置，文件都在：/home/hadoop/hadoop/etc/hadoop路径下</p><p>2、配置core-site.xml</p><p>修改Hadoop核心配置文件/home/hadoop/hadoop/etc/hadoop/core-site.xml，通过fs.default.name指定NameNode的IP地址和端口号，通过hadoop.tmp.dir指定hadoop数据存储的临时文件夹。<br><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="params">&lt;configuration&gt;</span></span><br><span class="line">　　 <span class="params">&lt;property&gt;</span></span><br><span class="line">　　　　<span class="params">&lt;name&gt;</span>hadoop.tmp.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">　　　　<span class="params">&lt;value&gt;</span>file:<span class="meta-keyword">/home/</span>hadoop<span class="meta-keyword">/hadoop/</span>tmp<span class="params">&lt;/value&gt;</span></span><br><span class="line">　　　　<span class="params">&lt;description&gt;</span>Abase for other temporary directories.<span class="params">&lt;/description&gt;</span></span><br><span class="line">     <span class="params">&lt;/property&gt;</span></span><br><span class="line">     <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>fs.defaultFS<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>hdfs:<span class="comment">//hadoop-master:9000&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure></p><blockquote><p>特别注意：如没有配置hadoop.tmp.dir参数，此时系统默认的临时目录为：/tmp/hadoo-hadoop。而这个目录在每次重启后都会被删除，必须重新执行format才行，否则会出错。</p></blockquote><p>3、配置hdfs-site.xml：</p><p>修改HDFS核心配置文件/usr/local/hadoop/etc/hadoop/hdfs-site.xml，通过dfs.replication指定HDFS的备份因子为3，通过dfs.name.dir指定namenode节点的文件存储目录，通过dfs.data.dir指定datanode节点的文件存储目录。<br><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="params">&lt;configuration&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.replication<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">2</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.name.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="meta-keyword">/home/</span>hadoop<span class="meta-keyword">/hadoop/</span>hdfs/name<span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.data.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="meta-keyword">/home/</span>hadoop<span class="meta-keyword">/hadoop/</span>hdfs/data<span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure></p><p>4、配置mapred-site.xml</p><p>拷贝mapred-site.xml.template为mapred-site.xml，在进行修改</p><blockquote><p>cp /home/hadoop/hadoop/etc/hadoop/mapred-site.xml.template /home/hadoop/hadoop/etc/hadoop/mapred-site.xml<br>vim /home/hadoop/hadoop/etc/hadoop/mapred-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.job.tracker<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop-master:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p></blockquote><p>5、配置yarn-site.xml<br>后面两个property为2.7.4 nodemanager不启动添加，解决内存太小问题<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 启动nodemanager value 为cpu核数 查看每个物理CPU中core的个数(即核数) cat /proc/cpuinfo| grep "cpu cores"| uniq --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>8192<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>6、配置masters文件</p><p>修改/home/hadoop/hadoop/etc/hadoop/masters文件，该文件指定namenode节点所在的服务器机器。删除localhost，添加namenode节点的主机名hadoop-master；不建议使用IP地址，因为IP地址可能会变化，但是主机名一般不会变化。</p><blockquote><p>vi /home/hadoop/hadoop/etc/hadoop/masters<br>## 内容<br>hadoop-master</p></blockquote><p>7、修改hadoop-env.sh</p><blockquote><p>vi /usr/local/hadoop/etc/hadoop/hadoop-env.sh<br>## 配置项<br>export JAVA_HOME=/usr/java/jdk1.8.0_152</p></blockquote><p>8、配置slaves文件（Master主机特有）</p><p>修改/home/hadoop/hadoop/etc/hadoop/slaves文件，该文件指定哪些服务器节点是datanode节点。删除locahost，添加所有datanode节点的主机名，如下所示。</p><blockquote><p>vi /home/hadoop/hadoop/etc/hadoop/slaves<br>## 内容<br>hadoop-slave1<br>hadoop-slave2<br>hadoop-slave3</p></blockquote><p><strong>配置hadoop-slave的hadoop环境</strong></p><p>下面以配置hadoop-slave1的hadoop为例进行演示，用户需参照以下步骤完成其他hadoop-slave2~3服务器的配置。</p><p>1）复制hadoop到hadoop-slave1节点</p><blockquote><p>scp -r /home/hadoop/hadoop hadoop-slave1:/home/hadoop/</p></blockquote><p>登录hadoop-slave1服务器，删除slaves内容</p><blockquote><p>rm -rf /home/hadoop/hadoop/etc/hadoop/slaves</p></blockquote><p>2）配置环境变量</p><blockquote><p>vi /etc/profile<br>## 内容<br>export HADOOP_HOME= /home/hadoop/hadoop<br>export PATH=\$PATH:\$HADOOP_HOME/bin</p></blockquote><p>使得hadoop命令在当前终端立即生效；</p><blockquote><p>source /etc/profile<br>期间报了一个错误<br>-bash: export: ` /home/hadoop/hadoop’: not a valid identifier<br>原因是/home前面多个空格</p></blockquote><p>依次配置其它slave服务</p><p>###启动集群<br>1、格式化HDFS文件系统</p><p>进入master的~/hadoop目录，执行以下操作</p><blockquote><p>bin/hadoop namenode -format</p></blockquote><p>格式化namenode，第一次启动服务前执行的操作，以后不需要执行。</p><p>2、然后启动hadoop：</p><blockquote><p>sbin/start-all.sh</p></blockquote><p>3、使用jps命令查看运行情况</p><blockquote><p>#master 执行 jps查看运行情况<br>25928 SecondaryNameNode<br>25742 NameNode<br>26387 Jps<br>26078 ResourceManager</p></blockquote><blockquote><p>#slave 执行 jps查看运行情况<br>24002 NodeManager<br>23899 DataNode<br>24179 Jps</p></blockquote><p>4、命令查看Hadoop集群的状态</p><p>通过简单的jps命令虽然可以查看HDFS文件管理系统、MapReduce服务是否启动成功，但是无法查看到Hadoop整个集群的运行状态。我们可以通过hadoop dfsadmin -report进行查看。用该命令可以快速定位出哪些节点挂掉了，HDFS的容量以及使用了多少，以及每个节点的硬盘使用情况。</p><blockquote><p>hadoop dfsadmin -report</p></blockquote><p>输出结果：</p><blockquote><p>Configured Capacity: 50108030976 (46.67 GB)<br>Present Capacity: 41877471232 (39.00 GB)<br>DFS Remaining: 41877385216 (39.00 GB)<br>DFS Used: 86016 (84 KB)<br>DFS Used%: 0.00%<br>Under replicated blocks: 0<br>Blocks with corrupt replicas: 0<br>Missing blocks: 0<br>Missing blocks (with replication factor 1): 0<br>……</p></blockquote><p>5、hadoop 重启</p><blockquote><p>sbin/stop-all.sh<br>sbin/start-all.sh</p></blockquote><ul><li><strong>参考</strong>：纯洁的微笑 :<a href="http://www.ityouknow.com/hadoop/2017/07/24/hadoop-cluster-setup.html" target="_blank" rel="noopener">hadoop分布式集群搭建</a></li></ul><p>[Create：2018年8月22日]</p><hr><hr>]]></content>
    
    <summary type="html">
    
      本文用以记录hadoop分布式集群搭建过程
    
    </summary>
    
      <category term="Hadoop" scheme="https://mydiscat.cn/categories/Hadoop/"/>
    
    
      <category term="Java" scheme="https://mydiscat.cn/tags/Java/"/>
    
      <category term="Hadoop" scheme="https://mydiscat.cn/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop、Hbase HA高可用集群搭建</title>
    <link href="https://mydiscat.cn/category/2018/10/31/Hbase%20distributed%20cluster%20construction.html"/>
    <id>https://mydiscat.cn/category/2018/10/31/Hbase distributed cluster construction.html</id>
    <published>2018-10-30T16:00:00.000Z</published>
    <updated>2018-10-31T12:32:34.095Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p><strong>基础环境准备</strong><br>根据前面<a href="https://mydiscat.cn/category/2018/10/31/Hadoop distributed cluster construction.html">hadoop集群搭建</a>、<a href="https://mydiscat.cn/category/2018/10/31/Hbase distributed cluster construction.html">hbase集群搭建</a>添加外部zookeeper集群</p><blockquote><p>下载zookeeper： <a href="http://mirrors.hust.edu.cn/apache/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gz" target="_blank" rel="noopener">zookeeper-3.4.13</a></p></blockquote><p><strong>zookeeper安装</strong></p><p>1、下载及安装<br>解压到/home/zookeeper/目录下：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf zookeeper-<span class="number">3.4</span>.<span class="number">13</span><span class="selector-class">.tar</span><span class="selector-class">.gz</span> -C /home/zookeeper/</span><br></pre></td></tr></table></figure></p><a id="more"></a><p>2、拷贝 zoo_sample.cfg<br>进入zookeeper的conf目录，拷贝zoo_sample.cfg并重命名为zoo.cfg ：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> zookeeper-<span class="number">3.4</span>.<span class="number">13</span>/<span class="keyword">conf</span>/</span><br><span class="line"><span class="keyword">cp</span> zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure></p><p>3、修改 zoo.cfg<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">vi</span> <span class="selector-tag">zoo</span><span class="selector-class">.cfg</span></span><br></pre></td></tr></table></figure></p><p>修改如下，若原文件没有dataDir则直接添加：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dataDir=<span class="regexp">/home/</span>zookeeper<span class="regexp">/zookeeper-3.4.13/</span>data/zkData</span><br><span class="line"><span class="comment">//在最后添加，指定zookeeper集群主机及端口，机器数必须为奇数</span></span><br><span class="line">server<span class="number">.1</span>=hadoop-<span class="string">master:</span><span class="number">2888</span>:<span class="number">3888</span></span><br><span class="line">server<span class="number">.2</span>=hadoop-<span class="string">slave1:</span><span class="number">2888</span>:<span class="number">3888</span></span><br><span class="line">server<span class="number">.3</span>=hadoop-<span class="string">slave2:</span><span class="number">2888</span>:<span class="number">3888</span></span><br></pre></td></tr></table></figure></p><p>4、创建并编辑myid<br>//在zookeeper根目录下创建zoo.cfg中配置的目录<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir data/zkData/ -p</span><br><span class="line"><span class="comment">//创建并编辑文件</span></span><br><span class="line">vi myid</span><br><span class="line"><span class="comment">//输入1，即表示当前机器为在zoo.cfg中指定的server.1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="comment">//保存退出</span></span><br><span class="line">:wq</span><br></pre></td></tr></table></figure></p><p>5、拷贝zookeeper到其他机器<br>上述操作是在hadoop-master机器上进行的，要将zookeeper拷贝到其他zookeeper集群机器上：<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd <span class="regexp">/home/</span>zookeeper</span><br><span class="line">scp -r zookeeper-<span class="number">3.4</span>.<span class="number">13</span><span class="regexp">/ hadoop-slave1:/</span>home<span class="regexp">/zookeeper/</span></span><br><span class="line">scp -r zookeeper-<span class="number">3.4</span>.<span class="number">13</span><span class="regexp">/ hadoop-slave2:/</span>home<span class="regexp">/zookeeper/</span></span><br></pre></td></tr></table></figure></p><p>6、修改其他机器的myid文件<br>myid文件是作为当前机器在zookeeper集群的标识，这些标识在zoo.cfg文件中已经配置好了，但是之前在hadoop-master这台机器上配置的myid为1，所以还需要修改其他机器的myid文件：<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">//</span>在hadoop-slave1机器上</span><br><span class="line">echo <span class="number">2</span> &gt; <span class="regexp">/home/</span>zookeeper<span class="regexp">/zookeeper-3.4.13/</span>data<span class="regexp">/zkData/myi</span>d</span><br><span class="line"><span class="regexp">//</span>在hadoop-slave2机器上</span><br><span class="line">echo <span class="number">3</span> &gt; <span class="regexp">/home/</span>zookeeper<span class="regexp">/zookeeper-3.4.13/</span>data<span class="regexp">/zkData/myi</span>d</span><br></pre></td></tr></table></figure></p><p>7、配置环境变量 vim  /etc/profile<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">添加：</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">ZOOKEEPER_HOME</span>=/home/zookeeper/zookeeper-3.4.13</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$ZOOKEEPER_HOME/bin</span><br><span class="line">其它服务器同样配置</span><br></pre></td></tr></table></figure></p><p>配置生效 source /etc/profile<br>8、启动zookeeper集群<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cd zookeeper<span class="number">-3.4</span><span class="number">.11</span>/bin/</span><br><span class="line"><span class="comment">//分别在master188、master189、slave190上启动</span></span><br><span class="line">/home/zookeeper/zookeeper<span class="number">-3.4</span><span class="number">.13</span>/bin/zkServer.sh start</span><br><span class="line"></span><br><span class="line"><span class="comment">//查看状态</span></span><br><span class="line">/home/zookeeper/zookeeper<span class="number">-3.4</span><span class="number">.13</span>/bin/zkServer.sh  status</span><br><span class="line">三台机器的zookeeper状态必须只有一个leader，其他都是follower。</span><br><span class="line"></span><br><span class="line"><span class="comment">//查看进程，若有QuorumpeerMain，则启动成功</span></span><br><span class="line">jps</span><br><span class="line"><span class="comment">//停止</span></span><br><span class="line">/home/zookeeper/zookeeper<span class="number">-3.4</span><span class="number">.13</span>/bin/zkServer.sh stop</span><br></pre></td></tr></table></figure></p><p><strong>hadoop添加zookeeper</strong></p><p>1、配置core-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">添加：</span><br><span class="line">  <span class="comment">&lt;!-- 指定ZooKeeper集群的地址和端口。注意，数量一定是奇数，且不少于三个节点--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">修改：</span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop-master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">为：</span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>2、配置hdfs-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 指定副本数，不能超过机器节点数  --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 为namenode集群定义一个services name --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- nameservice 包含哪些namenode，为各个namenode起名 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-master,hadoop-slave1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 名为hadoop-master的namenode的rpc地址和端口号，rpc用来和datanode通讯 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.hadoop-master<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 名为hadoop-slave1的namenode的rpc地址和端口号，rpc用来和datanode通讯 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.hadoop-slave1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-slave1:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!--名为hadoop-master的namenode的http地址和端口号，用来和web客户端通讯 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.ns1.hadoop-master<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-master:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 名为hadoop-slave1的namenode的http地址和端口号，用来和web客户端通讯 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.ns1.hadoop-slave1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-slave1:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">&lt;!-- namenode间用于共享编辑日志的journal节点列表 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://hadoop-master:8485;hadoop-slave1:8485;hadoop-slave2:8485/ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 指定该集群出现故障时，是否自动切换到另一台namenode --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- journalnode 上用于存放edits日志的目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/hadoop/tmp/data/dfs/journalnode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 客户端连接可用状态的NameNode所用的代理类 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 一旦需要NameNode切换，使用ssh方式进行操作 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 如果使用ssh进行故障切换，使用ssh通信时用的密钥存储的位置 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- connect-timeout超时时间 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.connect-timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>30000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/hadoop/hdfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/hadoop/hdfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>3、配置 mapred-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">取消：</span><br><span class="line"> <span class="comment">&lt;!-- &lt;property&gt;</span></span><br><span class="line"><span class="comment">        &lt;name&gt;mapred.job.tracker&lt;/name&gt;</span></span><br><span class="line"><span class="comment">        &lt;value&gt;http://hadoop-master:9001&lt;/value&gt;</span></span><br><span class="line"><span class="comment">  &lt;/property&gt;--&gt;</span></span><br></pre></td></tr></table></figure></p><p>4、配置 yarn-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 启用HA高可用性 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 指定resourcemanager的名字 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yrc<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 使用了2个resourcemanager,分别指定Resourcemanager的地址 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">&lt;!-- 指定rm1的地址 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">&lt;!-- 指定rm2的地址  --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-slave1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">&lt;!-- 指定当前机器hadoop-master作为rm1 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">&lt;!-- 指定zookeeper集群机器 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">&lt;!-- NodeManager上运行的附属服务，默认是mapreduce_shuffle --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>5、vi slaves<br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop-<span class="literal">master</span></span><br><span class="line">hadoop-slave1</span><br><span class="line">hadoop-slave2</span><br></pre></td></tr></table></figure></p><p><strong>拷贝hadoop到其他机器</strong></p><p>1、拷贝<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r <span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop hadoop-slave1:/</span>home<span class="regexp">/hadoop/</span></span><br><span class="line">scp -r <span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop hadoop-slave2:/</span>home<span class="regexp">/hadoop/</span></span><br></pre></td></tr></table></figure></p><p>2、修改yarn-site.xml<br>在hadoop-slave1机器，即ResourceManager备用主节点上修改如下属性，表示当前机器作为rm2:：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>同时删除hadoop-slave2机器上的该属性对，因为hadoop-slave2机器并不作为ResourceManager。</p><p>####启动Hadoop<br>1、启动zookeeper<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/home/</span>zookeeper<span class="regexp">/zookeeper-3.4.13/</span>bin<span class="regexp">/zkServer.sh start</span></span><br></pre></td></tr></table></figure></p><p>2、启动所有Journalnode<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop/</span>sbin<span class="regexp">/hadoop-daemon.sh start  journalnode</span></span><br></pre></td></tr></table></figure></p><p>3、格式化master namenode（这里直接复制会有问题，最好手动输入）（第一次启动操作）<br><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta-keyword">/home/</span>hadoop<span class="meta-keyword">/hadoop/</span>bin/hdfs namenode –format</span><br><span class="line"></span><br><span class="line"><span class="meta">#启动 master namenode </span></span><br><span class="line"><span class="meta-keyword">/home/</span>hadoop<span class="meta-keyword">/hadoop/</span>sbin/hadoop-daemon.sh start namenode</span><br><span class="line"></span><br><span class="line"><span class="meta">#master2上同步master namenode元数据 </span></span><br><span class="line">bin/hdfs namenode -bootstrapStandby</span><br><span class="line"><span class="meta">#格式化 zk（在hadoop-master即可）（这里直接复杂会有问题，最好手动输入）</span></span><br><span class="line"></span><br><span class="line"><span class="meta-keyword">/home/</span>hadoop<span class="meta-keyword">/hadoop/</span>bin/hdfs zkfc –formatZK</span><br></pre></td></tr></table></figure></p><p>4、启动HDFS、YARN、ZookeeperFailoverController<br><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta-keyword">/home/</span>hadoop<span class="meta-keyword">/hadoop/</span>sbin/start-dfs.sh</span><br><span class="line"><span class="comment">//jps验证，显示NameNode和DataNode</span></span><br><span class="line"></span><br><span class="line"><span class="meta-keyword">/home/</span>hadoop<span class="meta-keyword">/hadoop/</span>sbin/start-yarn.sh</span><br><span class="line"><span class="comment">//jps 验证，显示ResourceManager和NodeManager</span></span><br></pre></td></tr></table></figure></p><p>4、启动resourcemanager（hadoop-master、hadoop-slave1）<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop/</span>sbin<span class="regexp">/yarn-daemon.sh start resourcemanager</span></span><br></pre></td></tr></table></figure></p><p>5、启动zkfc来监控NN状态（在hadoop-master、hadoop-slave1）<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/home/</span>hadoop<span class="regexp">/hadoop/</span>sbin<span class="regexp">/hadoop-daemon.sh start zkfc</span></span><br></pre></td></tr></table></figure></p><p>启动命令：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#hadoop-master</span><br><span class="line">/home/hadoop/hadoop/sbin/start-all.sh</span><br><span class="line">/home/hadoop/hadoop/sbin/hadoop-daemon<span class="selector-class">.sh</span> start zkfc</span><br><span class="line"></span><br><span class="line">#hadoop-slave1</span><br><span class="line">/home/hadoop/hadoop/sbin/yarn-daemon<span class="selector-class">.sh</span> start resourcemanager</span><br><span class="line">/home/hadoop/hadoop/sbin/hadoop-daemon<span class="selector-class">.sh</span> start zkfc</span><br></pre></td></tr></table></figure></p><p>停止命令：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#hadoop-master</span><br><span class="line">/home/hadoop/hadoop/sbin/stop-all.sh</span><br><span class="line">/home/hadoop/hadoop/sbin/hadoop-daemon<span class="selector-class">.sh</span> stop zkfc</span><br><span class="line"></span><br><span class="line">#hadoop-slave1</span><br><span class="line">/home/hadoop/hadoop/sbin/yarn-daemon<span class="selector-class">.sh</span> stop resourcemanager</span><br><span class="line">/home/hadoop/hadoop/sbin/hadoop-daemon<span class="selector-class">.sh</span> stop zkfc</span><br></pre></td></tr></table></figure></p><p>启动所有进程显示：<br><img src="https://upload-images.jianshu.io/upload_images/6273500-862219dd55729e0b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="启动项"></p><p><strong>错误处理：</strong><br>1、NameNode is not formatted<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">原因:  Path /home/hadoop/hadoop/hdfs/name should be specified as <span class="selector-tag">a</span> URI <span class="keyword">in</span> configura</span><br><span class="line">tion files.</span><br><span class="line">方法:把dfs<span class="selector-class">.namenode</span><span class="selector-class">.name</span><span class="selector-class">.dir</span>、dfs<span class="selector-class">.datanode</span><span class="selector-class">.data</span><span class="selector-class">.dir</span>的原路径格式如/usr/mywind/name改成file:/usr/mywind/name，即使用完全路径。</span><br><span class="line">还有个原因：格式化命令复制进去运行报错，手动输入正常</span><br></pre></td></tr></table></figure></p><p><strong>测试</strong><br>wordcount程序测试，在本地创建一个测试文件，并上传到hdfs上<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-id">#https</span>:<span class="comment">// 为下面文字加颜色</span></span><br><span class="line">https:<span class="comment">//</span></span><br><span class="line"></span><br><span class="line">#创建一个测试文件</span><br><span class="line"> vim test<span class="selector-class">.txt</span> </span><br><span class="line">#上传到hdfs上</span><br><span class="line">hadoop fs -put test<span class="selector-class">.txt</span> /input</span><br><span class="line">#查询hdfs上面是否存在input文件</span><br><span class="line">hadoop fs -ls /input</span><br><span class="line">#计算</span><br><span class="line"> hadoop jar hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-<span class="number">2.7</span>.<span class="number">4</span><span class="selector-class">.jar</span> wordcount /<span class="selector-tag">input</span> /output1</span><br><span class="line">#查看输出结果</span><br><span class="line">hadoop fs -cat /output1/part*</span><br></pre></td></tr></table></figure></p><p><img src="https://upload-images.jianshu.io/upload_images/6273500-fb526b6ff7c7bb7b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="结果"></p><p><strong>Hbase安装配置</strong><br>进入/home/hbase/hbase/conf/目录，修改配置文件：<br>1、配置 hbase-env.sh<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//配置JDK</span></span><br><span class="line"><span class="keyword">export</span> JAVA_HOME=<span class="regexp">/usr/</span>java/</span><br><span class="line"></span><br><span class="line"><span class="comment">//保存pid文件</span></span><br><span class="line"><span class="keyword">export</span> HBASE_PID_DIR=<span class="regexp">/home/</span>hbase/hbase/data/hbase/pids</span><br><span class="line"></span><br><span class="line"><span class="comment">//修改HBASE_MANAGES_ZK，禁用HBase自带的Zookeeper，因为我们是使用独立的Zookeeper</span></span><br><span class="line"><span class="keyword">export</span> HBASE_MANAGES_ZK=<span class="literal">false</span></span><br></pre></td></tr></table></figure></p><p>2、配置 hbase-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 设置HRegionServers共享目录，请加上端口号 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master188:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 指定HMaster主机 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master188:60000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 启用分布式模式 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 指定Zookeeper集群位置 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-master:2181,hadoop-slave1:2181,hadoop-slave2:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 指定独立Zookeeper安装路径 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/zookeeper/zookeeper-3.4.13<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 指定ZooKeeper集群端口 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.clientPort<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>3）vi regionservers<br>修改regionservers文件，因为当前是使用独立的Zookeeper集群，所以要指定RegionServers所在机器：<br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop-<span class="literal">master</span></span><br><span class="line">hadoop-slave1</span><br><span class="line">hadoop-slave2</span><br></pre></td></tr></table></figure></p><p>4）创建pid文件保存目录<br>在/home/hbase/hbase/目录下：<br><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">mkdir</span> <span class="class"><span class="keyword">data</span>/hbase/pids -p</span></span><br></pre></td></tr></table></figure></p><p>3、拷贝HBase到其他机器<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r <span class="regexp">/home/</span>hbase<span class="regexp">/hbase/</span> hadoop-<span class="string">slave1:</span><span class="regexp">/home/</span>hadoop/</span><br><span class="line">scp -r <span class="regexp">/home/</span>hbase<span class="regexp">/hbase/</span> hadoop-<span class="string">slave2:</span><span class="regexp">/home/</span>hadoop/</span><br></pre></td></tr></table></figure></p><p>4、启动HBase<br>在主节点上启动HBase（主节点指NameNode状态为active的节点，非指文中的机器声明）：<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/home/</span>hbase<span class="regexp">/hbase/</span>bin<span class="regexp">/start-hbase.sh</span></span><br></pre></td></tr></table></figure></p><p>5、查看HMaster、Regionserver进程是否启动<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br><span class="line">注意：此时Hadoop集群应处于启动状态，并且是在主节点执行<span class="keyword">start</span>-hbase.sh启动HBase集群，否则HMaster进程将在启动几秒后消失，</span><br><span class="line">而备用的HMaster进程需要在备用主节点单独启动，命令是：./hbase-daemon.sh <span class="keyword">start</span> <span class="keyword">master</span>。</span><br><span class="line"></span><br><span class="line">在备用主节点启动HMaster进程，作为备用HMaster：</span><br><span class="line">/home/hbase/hbase/<span class="keyword">bin</span>/hbase-daemon.sh <span class="keyword">start</span> <span class="keyword">master</span></span><br></pre></td></tr></table></figure></p><p>5、HA高可用测试<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">在浏览器中输入 ip:16010 ，查看主节点和备用主节点上的HMaster的状态，在备用主节点的web界面中，</span><br><span class="line">可以看到“Current Active Master: master188”，表示当前HBase主节点是master188机器；</span><br><span class="line"></span><br><span class="line">主节点<span class="comment">---&gt;备用主节点</span></span><br><span class="line">这里的主节点指使用<span class="keyword">start</span>-hbase.sh命令启动HBase集群的机器</span><br><span class="line"></span><br><span class="line"><span class="keyword">kill</span>掉主节点的HMaster进程，在浏览器中查看备用主节点的HBase是否切换为active；</span><br><span class="line"></span><br><span class="line">若上述操作成功，则在主节点启动被杀死的HMaster进程：</span><br><span class="line"></span><br><span class="line">/home/hbase/hbase/<span class="keyword">bin</span>/hbase-daemon.sh <span class="keyword">start</span> <span class="keyword">master</span></span><br><span class="line"></span><br><span class="line">然后，<span class="keyword">kill</span>掉备用主节点的HMaster进程，在浏览器中查看主节点的HBase是否切换为active，若操作成功，则HBase高可用集群搭建完成；</span><br></pre></td></tr></table></figure></p><p>6、HBase基本操作<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//启动HBase</span></span><br><span class="line">[root@vnet ~] start-hbase.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">//进入HBase Shell</span></span><br><span class="line">[root@vnet ~] hbase shell</span><br><span class="line"></span><br><span class="line"><span class="comment">//查看当前HBase有哪些表</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; list</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建表t_user，cf1和cf2是列族，列族一般不超过3个</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; create <span class="string">'t_user'</span>,<span class="string">'cf1'</span>,<span class="string">'cf2'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//获得表t_user的描述信息</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; describe <span class="string">'t_user'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//禁用表</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; disable <span class="string">'t_user'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//删除表，删除表之前要先把表禁用掉</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; drop <span class="string">'t_user'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//查询表是否存在</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; exists <span class="string">'t_user'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//查看全表数据</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; scan <span class="string">'t_user'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//插入数据，分别是表名、key、列（列族：具体列）、值。HBase是面向列的数据库，列可无限扩充</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; put <span class="string">'t_user'</span> ,<span class="string">'001'</span>,<span class="string">'cf1:name'</span>,<span class="string">'chenxj'</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; put <span class="string">'t_user'</span> ,<span class="string">'001'</span>,<span class="string">'cf1:age'</span>,<span class="string">'18'</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; put <span class="string">'t_user'</span> ,<span class="string">'001'</span>,<span class="string">'cf2:sex'</span>,<span class="string">'man'</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; put <span class="string">'t_user'</span> ,<span class="string">'002'</span>,<span class="string">'cf1:name'</span>,<span class="string">'chenxj'</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; put <span class="string">'t_user'</span> ,<span class="string">'002'</span>,<span class="string">'cf1:address'</span>,<span class="string">'fuzhou'</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; put <span class="string">'t_user'</span> ,<span class="string">'002'</span>,<span class="string">'cf2:sex'</span>,<span class="string">'man'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//获取数据，可根据key、key和列族等进行查询</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; get <span class="string">'t_user'</span>,<span class="string">'001'</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; get <span class="string">'t_user'</span>,<span class="string">'002'</span>,<span class="string">'cf1'</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:&gt; get <span class="string">'t_user'</span>,<span class="string">'001'</span>,<span class="string">'cf1:age'</span></span><br></pre></td></tr></table></figure></p><p>7、集群启动结果<br>Hadoop + Zookeeper + HBase 高可用集群启动后，进程状态如下：</p><table><thead><tr><th>描述</th><th>hadoop-master</th><th>hadoop-slave1</th><th>hadoop-slave2</th></tr></thead><tbody><tr><td>HDFS主</td><td>NameNode</td><td>NameNode</td><td></td></tr><tr><td>HDFS从</td><td>DataNode</td><td>DataNode</td><td>DataNode</td></tr><tr><td>YARN主</td><td>ResourceManager</td><td>ResourceManager</td><td></td></tr><tr><td>YARN从</td><td>NodeManager</td><td>NodeManager</td><td>NodeManager</td></tr><tr><td>HBase主</td><td>HMaster</td><td>HMaster</td><td></td></tr><tr><td>HBase从</td><td>HRegionServer</td><td>HRegionServer</td><td>HRegionServer</td></tr><tr><td>Zookeeper独立进程</td><td>QuorumPeerMain</td><td>QuorumPeerMain</td><td>QuorumPeerMain</td></tr><tr><td>NameNodes数据同步</td><td>JournalNode</td><td>JournalNode</td><td>JournalNode</td></tr><tr><td>主备故障切换</td><td>DFSZKFailoverController</td><td>DFSZKFailoverController</td></tr></tbody></table><p><strong>总结</strong><br>需要注意的地方：</p><p>1）备用节点上的NameNode、ResourceManager、HMaster均需单独启动；<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon<span class="selector-class">.sh</span> start namenode</span><br><span class="line">yarn-daemon<span class="selector-class">.sh</span> start resourcemanager</span><br><span class="line">hbase-daemon<span class="selector-class">.sh</span> start master</span><br></pre></td></tr></table></figure></p><p>2）可以使用-forcemanual参数强制切换主节点与备用主节点，但强制切换后集群的自动故障转移将会失效，需要重新格式化zkfc：hdfs zdfc -formatZK;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">（这个没有测试）</span><br><span class="line">hdfs haadmin -transitionToActive/transitionToStandby  -forcemanual  hadoop-slave1</span><br><span class="line">yarn rmadmin -transitionToActive/transitionToStandby  -forcemanual  rm2</span><br></pre></td></tr></table></figure></p><p>3）在备用主节点同步主节点的元数据时，主节点的HDFS必须已经启动；</p><p>4）无法查看standby状态的节点上的hdfs；</p><p>5）格式化namenode时要先启动各个JournalNode机器上的journalnode进程：<br>否则会报journalnode拒绝连接错误<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon<span class="selector-class">.sh</span> start journalnode；</span><br></pre></td></tr></table></figure></p><p>6）若遇到问题，可以先考虑是哪个组件出现问题，然后查看该组件或与该组件相关的组件的日志信息；若各组件web页面无法访问，或存在其他连接问题，可以从「防火墙是否关闭」、「端口是否被占用」、「SSH」、「集群机器是否处于同一网段」内等角度考虑</p><p><strong>参考： <a href="https://www.cnblogs.com/sqchen/p/8080952.html" target="_blank" rel="noopener">Hadoop HA高可用集群搭建（Hadoop+Zookeeper+HBase）</a></strong></p><p>[Create：2018年8月23日]</p><hr><hr>]]></content>
    
    <summary type="html">
    
      本文用以记录Hadoop、Hbase HA高可用集群搭建过程
    
    </summary>
    
      <category term="Hbase" scheme="https://mydiscat.cn/categories/Hbase/"/>
    
    
      <category term="Java" scheme="https://mydiscat.cn/tags/Java/"/>
    
      <category term="Hadoop" scheme="https://mydiscat.cn/tags/Hadoop/"/>
    
      <category term="Hbase" scheme="https://mydiscat.cn/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>Hbase分布式集群搭建</title>
    <link href="https://mydiscat.cn/category/2018/10/31/Hbase%20distributed%20cluster%20construction.html"/>
    <id>https://mydiscat.cn/category/2018/10/31/Hbase distributed cluster construction.html</id>
    <published>2018-10-30T16:00:00.000Z</published>
    <updated>2018-10-31T12:32:14.869Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><p>hbase依赖于hadoop环境，搭建habase之前首先需要搭建好hadoop的完全集群环境，因此看这篇文章之前需要先看我的上一篇文章：<a href="https://mydiscat.cn/category/2018/10/31/Hadoop distributed cluster construction.html">hadoop集群搭建</a></p><p><strong>环境准备</strong></p><blockquote><ul><li>hbase软件包: <a href="http://mirror.bit.edu.cn/apache/hbase/1.3.1/hbase-1.3.1-bin.tar.gz" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/hbase/1.3.1/hbase-1.3.1-bin.tar.gz</a></li><li>完成hadoop集群环境搭建</li></ul></blockquote><p><strong>安装hbase</strong><br>1、首先在hadoop-master安装配置好之后，在复制到从节点(我使用的版本是1.2.6)<br><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget http:<span class="comment">//mirror.bit.edu.cn/apache/hbase/1.3.1/hbase-1.3.1-bin.tar.gz</span></span><br><span class="line"><span class="meta">#解压</span></span><br><span class="line">tar -xzvf hbase<span class="number">-1.3</span><span class="number">.1</span>-bin.tar.gz  -C /usr/local/</span><br><span class="line"><span class="meta">#重命名 </span></span><br><span class="line">mv hbase<span class="number">-1.3</span><span class="number">.1</span> hbase</span><br></pre></td></tr></table></figure></p><a id="more"></a><p>2、配置环境变量<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">编辑： vim /etc/profile</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HBASE_HOME</span>=/home/hbase/hbase</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$HBASE_HOME</span>/bin:$PATH</span><br><span class="line">生效： source /etc/profile</span><br></pre></td></tr></table></figure></p><p>3、修改系统变量ulimit</p><blockquote><p>ulimit -n 10240</p></blockquote><p><strong>配置文件</strong></p><p>hbase 相关的配置主要包括hbase-env.sh、hbase-site.xml、regionservers三个文件，都在 /usr/local/hbase/conf目录下面：</p><p>1、配置hbase-env.sh<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vim hbase-env.sh</span><br><span class="line"><span class="comment">#内容</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/java/jdk1.8.0_152</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HBASE_CLASSPATH</span>=/home/hbase/hbase/conf</span><br><span class="line"><span class="comment"># 此配置信息，设置由hbase自己管理zookeeper，不需要单独的zookeeper。</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HBASE_MANAGES_ZK</span>=<span class="literal">true</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HBASE_HOME</span>=/home/hbase/hbase</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HOME</span>=/home/hadoop/hadoop</span><br><span class="line"><span class="comment">#Hbase日志目录</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HBASE_LOG_DIR</span>=/home/hbase/hbase/logs</span><br></pre></td></tr></table></figure></p><p>2、配置 hbase-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop-master:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-master:60000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-master,hadoop-slave1,hadoop-slave2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>3、配置regionservers<br><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim <span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/hbase/</span>conf/regionservers</span><br><span class="line">hadoop-slave1</span><br><span class="line">hadoop-slave2</span><br></pre></td></tr></table></figure></p><p>4、 复制hbase到从节点中<br><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r <span class="meta-keyword">/home/</span>hbase/hbase hadoop-slave1:<span class="meta-keyword">/home/</span>hbase<span class="meta-keyword">/hbase/</span></span><br><span class="line">scp -r<span class="meta-keyword">/home/</span>hbase/hbase hadoop-slave2:<span class="meta-keyword">/home/</span>hbase<span class="meta-keyword">/hbase/</span></span><br></pre></td></tr></table></figure></p><p><strong>启动hbase</strong></p><p>启动仅在master节点上执行即可</p><blockquote><p>~/hbase/bin/start-hbase.sh<br>启动后，master上进程和slave进程列表</p></blockquote><p>master中的信息<br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@<span class="keyword">master</span> <span class="title">~]$</span> jps</span><br><span class="line"><span class="number">6225</span> Jps</span><br><span class="line"><span class="number">2897</span> SecondaryNameNode   <span class="comment"># hadoop进程</span></span><br><span class="line"><span class="number">2710</span> NameNode            <span class="comment"># hadoop master进程</span></span><br><span class="line"><span class="number">3035</span> ResourceManager     <span class="comment"># hadoop进程</span></span><br><span class="line"><span class="number">5471</span> HMaster             <span class="comment"># hbase master进程</span></span><br><span class="line"><span class="number">2543</span> HQuorumPeer         <span class="comment"># zookeeper进程</span></span><br></pre></td></tr></table></figure></p><p>salve中的信息<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop<span class="variable">@slave1</span> ~]<span class="variable">$ </span>jps</span><br><span class="line"><span class="number">4689</span> Jps</span><br><span class="line"><span class="number">2533</span> HQuorumPeer          <span class="comment"># zookeeper进程</span></span><br><span class="line"><span class="number">2589</span> DataNode             <span class="comment"># hadoop slave进程</span></span><br><span class="line"><span class="number">4143</span> HRegionServer        <span class="comment"># hbase slave进程</span></span><br></pre></td></tr></table></figure></p><p>因为hbase依赖于hadoop，因此启动和停止都是需要按照顺序进行</p><p>如果安装了独立的zookeeper<br><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">启动顺序: <span class="function"><span class="title">hadoop</span>-&gt;</span> <span class="function"><span class="title">zookeeper</span>-&gt;</span> hbase</span><br><span class="line">停止顺序：<span class="function"><span class="title">hbase</span>-&gt;</span> <span class="function"><span class="title">zookeeper</span>-&gt;</span> hadoop</span><br></pre></td></tr></table></figure></p><p>使用自带的zookeeper<br><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">启动顺序: <span class="function"><span class="title">hadoop</span>-&gt;</span> hbase</span><br><span class="line">停止顺序：<span class="function"><span class="title">hbase</span>-&gt;</span> hadoop</span><br></pre></td></tr></table></figure></p><p>重启hbase<br><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta-keyword">/home/</span>hbase<span class="meta-keyword">/hbase/</span>bin/stop-hbase.sh</span><br><span class="line"><span class="meta-keyword">/home/</span>hadoop<span class="meta-keyword">/hadoop/</span>sbin/stop-all.sh </span><br><span class="line"><span class="meta-keyword">/home/</span>hadoop<span class="meta-keyword">/hadoop/</span>sbin/start-all.sh </span><br><span class="line"><span class="meta-keyword">/home/</span>hbase<span class="meta-keyword">/hbase/</span>bin/start-hbase.sh</span><br></pre></td></tr></table></figure></p><p>hbase <a href="http://172.16.81.8:16010" target="_blank" rel="noopener">UI界面</a></p><p><strong>错误处理</strong></p><p>1、<a href="https://www.cnblogs.com/ThinkVenus/p/8042743.html" target="_blank" rel="noopener">启动hbase输出ignoring option PermSize=128m; support was removed in 8.0告警信息</a><br>解决办法：<br>由于JDK使用的是jdk1.8.0_65<br>hbase-env.sh注释掉以下：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configure PermSize. Only needed in JDK7. You can safely remove it for JDK8+</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HBASE_MASTER_OPTS</span>=<span class="string">"<span class="variable">$HBASE_MASTER_OPTS</span> -XX:PermSize=128m -XX:MaxPermSize=128m"</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HBASE_REGIONSERVER_OPTS</span>=<span class="string">"<span class="variable">$HBASE_REGIONSERVER_OPTS</span> -XX:PermSize=128m -XX:MaxPermSize=128m"</span></span><br></pre></td></tr></table></figure></p><p>2、hregionserver没有启动<br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">原因：在slave1、slave2主机中查看CST时间 </span><br><span class="line">[grid@slave1 bin]$ <span class="keyword">date</span> </span><br><span class="line"><span class="number">2018</span>年 <span class="number">08</span>月 <span class="number">22</span>日 星期三 <span class="number">18</span>:<span class="number">05</span>:<span class="number">23</span> CST</span><br><span class="line">在<span class="literal">master</span>主机中查看CST时间 </span><br><span class="line">[grid@<span class="keyword">master</span> <span class="title">bin</span>]$ <span class="keyword">date</span> </span><br><span class="line"><span class="number">2018</span>年 <span class="number">08</span>月 <span class="number">22</span>日 星期三 <span class="number">18</span>:<span class="number">00</span>:<span class="number">35</span> CST</span><br><span class="line">没错主从节点的系统日期是不一样的。 </span><br><span class="line">解决方法：把<span class="literal">master</span>主机的时间设置成和<span class="literal">slave</span>主机时间一致 </span><br><span class="line">[root@<span class="keyword">master</span> <span class="title">bin</span>]<span class="comment"># date -s 18:06:00</span></span><br><span class="line"><span class="number">2018</span>年 <span class="number">08</span>月 <span class="number">22</span>日 星期三 <span class="number">18</span>:<span class="number">06</span>:<span class="number">00</span> CST</span><br></pre></td></tr></table></figure></p><p>第二个原因，可以修改hbase默认的最大链接时间长一些。<br>HBase配置文件hbase-siter.xml中添加连接时长的属性<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master.maxclockskew<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>120000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p><em>参考:纯洁的微笑：<a href="https://www.cnblogs.com/ityouknow/p/7343996.html" target="_blank" rel="noopener">hbase分布式集群搭建</a></em></p><p>[Create：2018年8月22日]</p><hr><hr>]]></content>
    
    <summary type="html">
    
      本文用以记录Hbase分布式集群搭建过程
    
    </summary>
    
      <category term="Hbase" scheme="https://mydiscat.cn/categories/Hbase/"/>
    
    
      <category term="Java" scheme="https://mydiscat.cn/tags/Java/"/>
    
      <category term="Hbase" scheme="https://mydiscat.cn/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>开启 Hexo 博客之旅</title>
    <link href="https://mydiscat.cn/category/2018/10/30/Open%20the%20Hexo%20blog%20tour.html"/>
    <id>https://mydiscat.cn/category/2018/10/30/Open the Hexo blog tour.html</id>
    <published>2018-10-29T16:00:00.000Z</published>
    <updated>2018-10-31T12:32:19.973Z</updated>
    
    <content type="html"><![CDATA[<p class="description"></p><h2 id="Hexo-github-pages-搭建博客-，速度快的飞起，直接按网上的步骤开始"><a href="#Hexo-github-pages-搭建博客-，速度快的飞起，直接按网上的步骤开始" class="headerlink" title="Hexo + github pages 搭建博客 ，速度快的飞起，直接按网上的步骤开始"></a>Hexo + github pages 搭建博客 ，速度快的飞起，直接按网上的步骤开始</h2><p><strong>参考如下，可以直接按第二个去弄，主题是 next</strong></p><blockquote><ul><li>使用 hexo+github pages 搭建博客：<a href="http://laijianfeng.org/2018/05/使用hexo-github-pages搭建博客/" target="_blank" rel="noopener">http://laijianfeng.org/2018/05/使用hexo-github-pages搭建博客/</a></li></ul></blockquote><blockquote><ul><li><strong>打造个性化博客（极致详细）</strong>：<a href="https://reuixiy.github.io/technology/computer/computer-aided-art/2017/06/09/hexo-next-optimization.html" target="_blank" rel="noopener">https://reuixiy.github.io/technology/computer/computer-aided-art/2017/06/09/hexo-next-optimization.html</a></li><li>修改文章内链接样式｜hexo： <a href="https://blog.csdn.net/qw8880000/article/details/80235648" target="_blank" rel="noopener">https://blog.csdn.net/qw8880000/article/details/80235648</a></li><li>hexo 的 next 主题个性化教程：打造炫酷网站：<a href="https://blog.csdn.net/qq_33699981/article/details/72716951?utm_source=blogxgwz1" target="_blank" rel="noopener">https://blog.csdn.net/qq_33699981/article/details/72716951?utm_source=blogxgwz1</a></li><li>在 NexT 中使用 Valine 评论系统：<a href="https://reuixiy.github.io/technology/computer/computer-aided-art/2018/07/15/use-valine-in-theme-next.html" target="_blank" rel="noopener">https://reuixiy.github.io/technology/computer/computer-aided-art/2018/07/15/use-valine-in-theme-next.html</a></li></ul></blockquote><a id="more"></a><p><strong>安装没什么问题，个性化优化过程有点繁琐</strong> </p><h2 id="遇到问题有以下几点："><a href="#遇到问题有以下几点：" class="headerlink" title="遇到问题有以下几点："></a>遇到问题有以下几点：</h2><blockquote><ul><li>图片本地可以，上传到 github 除了主页，其他的跳转后显示有问题，图片路径修改为 github 的存储路径就好了，也可以用七牛云存储图片，但给的测试域名只有一个月有效期，长期的必须要备案的域名才行，后续在处理图片存储</li></ul></blockquote><blockquote><ul><li>页面 CSS 样式调整，比较费时，有前端的朋友找他们比较快速</li><li>用谷歌浏览器调试，内存飞速溢出，网站直接打不开，换火狐就好了（试了下 <strong>reuixiy</strong> 的博客，同样的问题，那就不是我安装的问题，后续有时间再看）</li><li>其他的问题在 reuixiy 的博客里都可以找到答案</li><li>YAMLException: end of the stream or a document separator is expected at line 2 好一番检查才发现第一行 — 变成 – 两个了 <strong>（特别注意符号，英文: 和空格）</strong></li><li>置顶无效，查看~/blog/node_modules/hexo-generator-index-pin-top/lib/generator.js 发现改成strict 的又还原回top<br>[Create：2018年10月30日]</li></ul></blockquote><hr><p>话不多说，接下来就是开始我的博客之旅~~~ </p><hr>]]></content>
    
    <summary type="html">
    
      汇集 Hexo 安装优化资源，以及使用中遇到的问题，解决方法，持续更新
    
    </summary>
    
      <category term="Hexo" scheme="https://mydiscat.cn/categories/Hexo/"/>
    
    
      <category term="Hexo" scheme="https://mydiscat.cn/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>开篇</title>
    <link href="https://mydiscat.cn/category/2018/10/29/begin.html"/>
    <id>https://mydiscat.cn/category/2018/10/29/begin.html</id>
    <published>2018-10-29T15:41:45.894Z</published>
    <updated>2018-10-31T09:42:58.104Z</updated>
    
    <content type="html"><![CDATA[<hr><p>一件事总要去做，最好就是现在，也许有点晚，总算开始了<br>Just do it</p>]]></content>
    
    <summary type="html">
    
      Hexo 博客安装成功
    
    </summary>
    
      <category term="随笔" scheme="https://mydiscat.cn/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="随笔" scheme="https://mydiscat.cn/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://mydiscat.cn/category/2018/10/29/hello-world.html"/>
    <id>https://mydiscat.cn/category/2018/10/29/hello-world.html</id>
    <published>2018-10-29T07:15:52.761Z</published>
    <updated>2018-10-31T05:21:24.416Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a><br><a id="more"></a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;&lt;h3 id=&quot;Create-a-new-post&quot;&gt;&lt;a href=&quot;#Create-a-new-post&quot; class=&quot;headerlink&quot; title=&quot;Create a new post&quot;&gt;&lt;/a&gt;Create a new post&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ hexo new &lt;span class=&quot;string&quot;&gt;&quot;My New Post&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://hexo.io/docs/writing.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Writing&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
